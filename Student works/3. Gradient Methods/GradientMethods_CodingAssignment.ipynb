{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36ddeea-2981-45a4-91ed-2a27dc6f1734",
   "metadata": {},
   "source": [
    "# Coding Assignment \"Gradient Methods\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf89ff1-2e35-4dcb-ac09-85bee08afde2",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48825306-2884-4883-bcaa-ef9232d2a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e995572-5300-4c58-bf1f-9de6b3376e83",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad8489-e1c9-4506-9382-5a1805f6576b",
   "metadata": {},
   "source": [
    "### 2.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb8bd8c-f9cf-45e5-9a9b-75f9ef1c8894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First data point:\n",
      "Latitude                        69.04277\n",
      "Longitude                       20.85091\n",
      "Timestamp            2023-12-31 18:00:00\n",
      "temp                               -16.5\n",
      "name         Enontekiö Kilpisjärvi Saana\n",
      "Name: 0, dtype: object\n",
      "\n",
      "******************************\n",
      "\n",
      "Another data point:\n",
      "Latitude                     69.757\n",
      "Longitude                    27.012\n",
      "Timestamp       2023-12-31 13:00:00\n",
      "temp                          -26.3\n",
      "name         Utsjoki Kevo Kevojärvi\n",
      "Name: 13, dtype: object\n",
      "\n",
      "******************************\n",
      "\n",
      "Unnormalized features of the first data point: \n",
      "Latitude: 69.04277\n",
      "Longitude: 20.85091\n",
      "Year: 2023.0\n",
      "Month: 12.0\n",
      "Day: 31.0\n",
      "Hour: 18.0\n",
      "Minute: 0.0\n",
      "\n",
      "******************************\n",
      "\n",
      "Label of first data point: -16.5\n"
     ]
    }
   ],
   "source": [
    "# Import the weather measurements.\n",
    "data = pd.read_csv('Assignment_MLBasicsData.csv')\n",
    "\n",
    "# We consider each temperature measurement (=a row in dataframe data) \n",
    "# as a separate data point.\n",
    "# Determine the total number of data points stored in csv file.\n",
    "nrdatapoints = len(data)\n",
    "\n",
    "# Print out the first data point (first row).\n",
    "print(\"First data point:\")\n",
    "print(data.iloc[0])\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "# Here is another data point. \n",
    "print(\"Another data point:\")\n",
    "print(data.iloc[13])\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "# We use normalized values of \n",
    "# latitude, longitude, year, mon, day, hour, minute (as float values) \n",
    "# as features of a data point.\n",
    "nrfeatures = 7 \n",
    "\n",
    "# The code snippet below extracts the features of the first data point (first row in dataframe data).\n",
    "date_object = datetime.strptime(data['Timestamp'].iloc[0], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extract individual components.\n",
    "latitude = data[\"Latitude\"].iloc[0]\n",
    "longitude = data[\"Longitude\"].iloc[0]\n",
    "year = float(date_object.year)\n",
    "month = float(date_object.month)\n",
    "day = float(date_object.day)\n",
    "hour = float(date_object.hour)\n",
    "minute = float(date_object.minute)\n",
    "\n",
    "print(\"Unnormalized features of the first data point: \")\n",
    "print(f\"Latitude: {latitude}\")\n",
    "print(f\"Longitude: {longitude}\")\n",
    "print(f\"Year: {year}\")\n",
    "print(f\"Month: {month}\")\n",
    "print(f\"Day: {day}\")\n",
    "print(f\"Hour: {hour}\")\n",
    "print(f\"Minute: {minute}\")\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "# We choose the temperature as the label (quantity of interest) of a data point.\n",
    "print(\"Label of first data point:\", data[\"temp\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a91255-b609-41a8-b0c7-ce924097f29c",
   "metadata": {},
   "source": [
    "### 2.2 Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89aa18b-bc5f-4d0e-b595-e9f31fa025bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The created feature matrix contains 19768 entries of 7 features each.\n",
      "The created label vector contains 19768 measurements.\n"
     ]
    }
   ],
   "source": [
    "# We next build the feature matrix X (each of its rows hold the features of a data point) \n",
    "# and the label vector y (whose entries hold the labels of data points).\n",
    "X = np.zeros((nrdatapoints, nrfeatures))\n",
    "y = np.zeros((nrdatapoints, 1))\n",
    "\n",
    "# Iterate over all rows in dataframe and create corresponding feature vector and label. \n",
    "for ind in data.index:\n",
    "    # Latitude of FMI station, normalized by 100. \n",
    "    lat = float(data['Latitude'].iloc[ind]) / 100\n",
    "    \n",
    "    # Longitude of FMI station, normalized by 100.\n",
    "    lon = float(data['Longitude'].iloc[ind]) / 100\n",
    "    \n",
    "    # Exctract the temperature value.\n",
    "    tmp = data['temp'].iloc[ind]\n",
    "    \n",
    "    # Read the date and time of the temperature measurement.\n",
    "    date_object = datetime.strptime(data['Timestamp'].iloc[ind], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Extract year, month, day, hour, minute, and second. \n",
    "    # Normalize these values to ensure features are in range [0,1].\n",
    "    year = float(date_object.year) / 2025\n",
    "    month = float(date_object.month) / 13\n",
    "    day = float(date_object.day) / 32\n",
    "    hour = float(date_object.hour) / 25\n",
    "    minute = float(date_object.minute) / 61\n",
    "    \n",
    "    # Store the data point's features and a label.\n",
    "    X[ind,:] = [lat, lon, year, month, day, hour, minute]\n",
    "    y[ind,:] = tmp\n",
    "\n",
    "print(f\"The created feature matrix contains {np.shape(X)[0]} entries of {np.shape(X)[1]} features each.\")\n",
    "print(f\"The created label vector contains {np.shape(y)[0]} measurements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf0e8e-d54a-4f67-9c2c-d5f8eb680233",
   "metadata": {},
   "source": [
    "### 2.3 Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a18f4b-2583-4619-a54a-4b7ce3357790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set consists of 100 data points.\n",
      "The validation set consists of 19668 data points.\n"
     ]
    }
   ],
   "source": [
    "# Define the number of data points used for training set.\n",
    "trainsize = 100\n",
    "\n",
    "# Split the dataset into training and validation set. \n",
    "Xtrain = X[:trainsize,:] \n",
    "Xval = X[trainsize:] \n",
    "ytrain = y[:trainsize] \n",
    "yval = y[trainsize:] \n",
    "\n",
    "print(f\"The training set consists of {np.shape(Xtrain)[0]} data points.\")\n",
    "print(f\"The validation set consists of {np.shape(Xval)[0]} data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0d122-a3f9-414a-872b-7add6b8b43e7",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc39c05-5fd4-4dc1-bde2-fb119de77baf",
   "metadata": {},
   "source": [
    "### 3.1 Ridge regression - Ready made implementation via Scikit-learn class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9bf864-f349-4d41-80ff-b5818f7c2f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Ridge Regression Diagnosis **********\n",
      "Training error:  34.48452921511405\n",
      "Validation error:  41.373355414751856\n"
     ]
    }
   ],
   "source": [
    "# Define the regularization parameter.\n",
    "regparam = 0.01\n",
    "\n",
    "# Create a ridge regression using scikit-learn class.\n",
    "ridge = Ridge(alpha=(trainsize*regparam), fit_intercept=False )\n",
    "\n",
    "# Train the linear model, i.e., \n",
    "# solve the ERM to obtain parameters of the linear model.\n",
    "ridge.fit(Xtrain, ytrain)\n",
    "Etrain = mean_squared_error(ytrain, ridge.predict(Xtrain))\n",
    "Eval = mean_squared_error(yval, ridge.predict(Xval))\n",
    "\n",
    "print(\"********** Ridge Regression Diagnosis **********\")\n",
    "print(\"Training error: \", Etrain)\n",
    "print(\"Validation error: \", Eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a9cc0-962d-4e9d-b621-be173c0579a1",
   "metadata": {},
   "source": [
    "### 3.2 Student task #1 - Ridge regression by gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24502ee-58a6-4404-8512-b0eba2a52047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Xtrain shape is: (100, 7)\n",
      "ytrain shape is: (100, 1)\n",
      "w shape is: (7, 1)\n",
      "Training error (GD): 32.335494337352685\n",
      "Validation error (GD): 39.0289899545525\n"
     ]
    }
   ],
   "source": [
    "# Define the initial parameters.\n",
    "N_iters = 1000 # The number of gradient steps.\n",
    "lrate = 0.1 # Learning rate\n",
    "\n",
    "####################TODO####################\n",
    "# TODO: Implement the GD Algorithm 2 for the objective function (2.27). Use\n",
    "#       the initialization w^{0} = 0. \n",
    "#       Use the resulting parameters (delivered by Algorithm 2) to compute the \n",
    "#       average squared error loss on the training set (= training error E_t) \n",
    "#       and the average squared error loss on the validation set (=validation error E_v)\n",
    "\n",
    "# raise NotImplementedError\n",
    "regparam = 0.01\n",
    "\n",
    "# Initialize weights\n",
    "w = np.zeros((nrfeatures, 1))\n",
    "\n",
    "print(nrfeatures)\n",
    "m = trainsize # 100\n",
    "# lambda_param = m * regparam\n",
    "# Gradient Descent\n",
    "\n",
    "print(f\"Xtrain shape is: {Xtrain.shape}\")\n",
    "print(f\"ytrain shape is: {ytrain.shape}\")\n",
    "print(f\"w shape is: {w.shape}\")\n",
    "\n",
    "for k in range(N_iters):\n",
    "    grad_fw = np.zeros((nrfeatures, 1))\n",
    "    for r in range(m):\n",
    "        x_r = Xtrain[r, :].reshape(-1, 1) # shape (7, 1)\n",
    "        # print(x_r.shape)\n",
    "        y_r = ytrain[r].item() # scalar\n",
    "        grad_fw += x_r * (y_r - w.T @ x_r) + regparam * x_r\n",
    "    grad_fw = - (2/m) * grad_fw\n",
    "    w = w - lrate * grad_fw\n",
    "\n",
    "# Calculate errors\n",
    "Etrain_GD = mean_squared_error(ytrain, Xtrain @ w)\n",
    "Eval_GD = mean_squared_error(yval, Xval @ w)\n",
    "\n",
    "print(\"Training error (GD):\", Etrain_GD)\n",
    "print(\"Validation error (GD):\", Eval_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6dfb1-99b7-4e4a-b41e-aabbd5ca3cae",
   "metadata": {},
   "source": [
    "### 3.3 Student task #2 - The optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16188f63-4cfb-4cbe-9ace-d95d182a2297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 69\u001b[0m\n\u001b[0;32m     64\u001b[0m Eval_GD_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lrate \u001b[38;5;129;01min\u001b[39;00m lrates:\n\u001b[0;32m     67\u001b[0m     \n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Run gradient descent\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     w_converge, k_converge \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     iterations_until_convergence\u001b[38;5;241m.\u001b[39mappend(k_converge)\n\u001b[0;32m     72\u001b[0m     Etrain_GD_list\u001b[38;5;241m.\u001b[39mappend(mean_squared_error(ytrain, Xtrain \u001b[38;5;241m@\u001b[39m w_converge))\n",
      "Cell \u001b[1;32mIn[25], line 54\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, lrate, regparam, tolerance)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#print(f\"Objective value: {objective_value}\")\u001b[39;00m\n\u001b[0;32m     53\u001b[0m w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m lrate \u001b[38;5;241m*\u001b[39m grad_fw\n\u001b[1;32m---> 54\u001b[0m objective_value_new \u001b[38;5;241m=\u001b[39m \u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#print(f\"Objective value new: {objective_value_new}\")\u001b[39;00m\n\u001b[0;32m     56\u001b[0m k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[25], line 23\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(X, y, w)\u001b[0m\n\u001b[0;32m     21\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[1;32m---> 23\u001b[0m     x_r \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# shape (7, 1)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# print(x_r.shape)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     y_r \u001b[38;5;241m=\u001b[39m y[r]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# scalar\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# You only have to try out the following values for the learning rate: \n",
    "lrates = np.linspace(0.28, 0.32, 20) # Learning rate\n",
    "# lrates = np.linspace(0.314, 0.32, 20) \n",
    "####################TODO####################\n",
    "# TODO: Modify the implemented GD Algorithm 2 \n",
    "#       to find the optimal learning rate value, \n",
    "#       such that the objective value converges to the optimum \n",
    "#       with the minimum number of gradient steps. \n",
    "# NOTE: Monitor the decrease in the objective function \n",
    "#       and compare it with the chosen tolerance as a stopping criterion.\n",
    "# HINT: The tolerance in the solution notebook was chosen 1e-10.\n",
    "\n",
    "# raise NotImplementedError\n",
    "\n",
    "N_iters_upper = 2000 # Upper limit on the number of iterations\n",
    "tolerance = 1e-10 # Tolerance for convergence\n",
    "regparam = 0.01\n",
    "\n",
    "m = trainsize # 100\n",
    "def objective_function(X, y, w):\n",
    "    objective_value = 0\n",
    "    for r in range(m):\n",
    "        x_r = X[r, :].reshape(-1, 1) # shape (7, 1)\n",
    "        # print(x_r.shape)\n",
    "        y_r = y[r].item() # scalar\n",
    "        objective_value += (y_r - w.T @ x_r) ** 2 \n",
    "    objective_value = (1/m) * objective_value + regparam * LA.norm(w) ** 2\n",
    "    return objective_value\n",
    "\n",
    "# def objective_function(X, y, w):\n",
    "#     trainingLoss = mean_squared_error(y, X @ w)\n",
    "#     return trainingLoss\n",
    "\n",
    "def compute_grad(X, y, w, regparam):\n",
    "    grad_fw = np.zeros((nrfeatures, 1))\n",
    "    for r in range(m):\n",
    "        x_r = X[r, :].reshape(-1, 1) # shape (7, 1)\n",
    "        # print(x_r.shape)\n",
    "        y_r = y[r].item() # scalar\n",
    "        grad_fw += x_r * (y_r - w.T @ x_r) + regparam * x_r\n",
    "    grad_fw = - (2/m) * grad_fw\n",
    "    return grad_fw\n",
    "\n",
    "def gradient_descent(X, y, lrate, regparam, tolerance):\n",
    "    w = np.zeros((nrfeatures, 1))\n",
    "    objective_value = objective_function(X, y, w)\n",
    "    objective_value_new = np.inf\n",
    "    k = 0\n",
    "    while abs(objective_value_new - objective_value) >= tolerance:\n",
    "        grad_fw = compute_grad(X, y, w, regparam)\n",
    "        objective_value = objective_function(X, y, w)\n",
    "        #print(f\"Objective value: {objective_value}\")\n",
    "        w = w - lrate * grad_fw\n",
    "        objective_value_new = objective_function(X, y, w)\n",
    "        #print(f\"Objective value new: {objective_value_new}\")\n",
    "        k += 1\n",
    "    return w, k\n",
    "\n",
    "# Corresponding list to store the number of iterations required to converge to the optimum\n",
    "# for each learning rate, including its training and validation error\n",
    "\n",
    "iterations_until_convergence = []\n",
    "Etrain_GD_list = []\n",
    "Eval_GD_list = []\n",
    "\n",
    "for lrate in lrates:\n",
    "    \n",
    "    # Run gradient descent\n",
    "    w_converge, k_converge = gradient_descent(Xtrain, ytrain, lrate, regparam, tolerance)\n",
    "    iterations_until_convergence.append(k_converge)\n",
    "\n",
    "    Etrain_GD_list.append(mean_squared_error(ytrain, Xtrain @ w_converge))\n",
    "    Eval_GD_list.append(mean_squared_error(yval, Xval @ w_converge))\n",
    "\n",
    "    print(f\"lrate: {lrate}, Converging k: {k_converge}, Etrain: {round(Etrain_GD_list[-1], 2)}, Eval: {round(Eval_GD_list[-1], 2)}\")\n",
    "\n",
    "# Plot the training and validation error as a function of the learning rate.\n",
    "    \n",
    "plt.plot(lrates, Etrain_GD_list, label='Training error')\n",
    "plt.plot(lrates, Eval_GD_list, label='Validation error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e227dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b04cedc500>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning rates vs iterations until convergence\n",
    "\n",
    "plt.plot(lrates, iterations_until_convergence, label='Iterations until convergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11637650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: For each learning rate in the given list, the number of iterations is larger than 2000?\n",
    "check = [i > 2000 for i in iterations_until_convergence]\n",
    "\n",
    "# Q2: For each learning rate in the given list, the number of iterations is smaller than 2000?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
